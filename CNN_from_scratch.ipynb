{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2128,
     "status": "ok",
     "timestamp": 1602090869106,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "VlpVl8zvFCvg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os, glob \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras   \n",
    "from keras.preprocessing.image import ImageDataGenerator        \n",
    "                                \n",
    "from keras.utils import np_utils \n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, Dropout, Dense, Flatten, Add, Activation,ReLU, BatchNormalization,AveragePooling2D\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46359,
     "status": "ok",
     "timestamp": 1602090913365,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "7-vR_N4fGA5S",
    "outputId": "69d6174d-75af-4e86-eb9d-64b04a1de968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YCn5JQtFCvr"
   },
   "source": [
    "### Load  and prepare cifar10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39997,
     "status": "ok",
     "timestamp": 1602090906988,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "g7a-cawcmg90",
    "outputId": "003760e9-aaaf-4bd7-c451-254e596cf88d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "dirc = 'D:/stat946'\n",
    "train_dir = glob.glob(dirc+'/train/train/*')\n",
    "x_train = np.asarray([cv2.imread(x_dir) for x_dir in train_dir])\n",
    "print('train data shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1602090869107,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "-MwAoeADhk-S"
   },
   "outputs": [],
   "source": [
    "#Read labes from \"train_labels.csv\" file based on training images' names\n",
    "y_train_df = pd.read_csv(dirc+'/train_labels.csv')\n",
    "y_train = [int(y_train_df[y_train_df.id == int(x_dir.split('\\\\')[-1].split('.')[0])].label)\\\n",
    "     for x_dir in train_dir] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 40427,
     "status": "ok",
     "timestamp": 1602090907420,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "S_UeSnvtnrnk"
   },
   "outputs": [],
   "source": [
    "test_dir = glob.glob(dirc+'/test/test/*')\n",
    "x_test = np.asarray([cv2.imread(x_dir) for x_dir in test_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 46690,
     "status": "ok",
     "timestamp": 1602090913702,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "RyvP2BsIFCvu"
   },
   "outputs": [],
   "source": [
    "#Typecast data samples to flot32. (usefull when using GPU)\n",
    "x_train = x_train.astype('float32')     \n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Scale pixles of data samples between 0 and 1.\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 46688,
     "status": "ok",
     "timestamp": 1602090913703,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "Dfi06lv3FCvz"
   },
   "outputs": [],
   "source": [
    "#convert train labels to one hot encoding\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split the training data to training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40871,
     "status": "ok",
     "timestamp": 1602090907871,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "a619cBLIoXwu",
    "outputId": "1bc38d46-ac0e-432b-f3b1-308cd3b61981"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_valid, y_train, y_valid = train_test_split(x_train,\n",
    "#                                                       y_train, test_size=0.2,\n",
    "#                                                       shuffle= True)\n",
    "\n",
    "# print('Split the training data to training and validation and test')\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_valid.shape[0], 'validation samples')\n",
    "# print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 46358,
     "status": "ok",
     "timestamp": 1602090913366,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "42INUST8FCvk"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline      \n",
    "np.random.seed(2020)\n",
    "batch_size = 64      #batch size\n",
    "num_classes = 10      #number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXFUSqnEFCv1"
   },
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 46687,
     "status": "ok",
     "timestamp": 1602090913704,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "qndfCaurFCv1"
   },
   "outputs": [],
   "source": [
    "# \"datagen\" will be used later for generating data in learning phase\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.25,    # randomly shift images horizontally (0.25 of total width)\n",
    "    height_shift_range=0.25,   # randomly shift images vertically (0.25 of total height)\n",
    "    horizontal_flip=True,      # randomly flip images\n",
    "    zoom_range=[0.5,1.5])      # randomly zoom in and zoom out. (less than 1: zoom in, i.e make image larger) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st convolutional layer\n",
    "model.add(Conv2D(input_shape=(32,32,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# 2nd convolutional layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 3rd convolutional layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 4th convolutional layer\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 5th convolutional layer\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Prediction layer (Fully connected)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1024,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 16,324,938\n",
      "Trainable params: 16,312,394\n",
      "Non-trainable params: 12,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XXLWTgWFCv4"
   },
   "source": [
    "##### Compiling Model\n",
    " * loss function, optimization method and the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1602090996388,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "WhGp_UeJVzmi"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning model and fit it on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mRasooli\\anaconda3.2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/350\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 2.3223 - accuracy: 0.2355\n",
      "Epoch 2/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.9113 - accuracy: 0.3316\n",
      "Epoch 3/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 1.8672 - accuracy: 0.3575\n",
      "Epoch 4/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.7415 - accuracy: 0.3984\n",
      "Epoch 5/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.6081 - accuracy: 0.4417\n",
      "Epoch 6/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.4919 - accuracy: 0.4851\n",
      "Epoch 7/350\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 1.4375 - accuracy: 0.5028\n",
      "Epoch 8/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.2966 - accuracy: 0.5533\n",
      "Epoch 9/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.2633 - accuracy: 0.5694\n",
      "Epoch 10/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.2866 - accuracy: 0.5636\n",
      "Epoch 11/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 1.1785 - accuracy: 0.5925\n",
      "Epoch 12/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.0800 - accuracy: 0.6314\n",
      "Epoch 13/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 1.0440 - accuracy: 0.6460\n",
      "Epoch 14/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0085 - accuracy: 0.6592\n",
      "Epoch 15/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.9771 - accuracy: 0.6702\n",
      "Epoch 16/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.9588 - accuracy: 0.6777\n",
      "Epoch 17/350\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.9039 - accuracy: 0.6941\n",
      "Epoch 18/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8887 - accuracy: 0.7016\n",
      "Epoch 19/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9011 - accuracy: 0.7002\n",
      "Epoch 20/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.8609 - accuracy: 0.7136\n",
      "Epoch 21/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.8488 - accuracy: 0.7185\n",
      "Epoch 22/350\n",
      "781/781 [==============================] - 36s 45ms/step - loss: 0.8290 - accuracy: 0.7231\n",
      "Epoch 23/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.8011 - accuracy: 0.7339\n",
      "Epoch 24/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.7918 - accuracy: 0.7361\n",
      "Epoch 25/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7763 - accuracy: 0.7388\n",
      "Epoch 26/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7606 - accuracy: 0.7448\n",
      "Epoch 27/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7348 - accuracy: 0.7540\n",
      "Epoch 28/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.7298 - accuracy: 0.7555\n",
      "Epoch 29/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.7115 - accuracy: 0.7613\n",
      "Epoch 30/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.6988 - accuracy: 0.7665\n",
      "Epoch 31/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.7190 - accuracy: 0.7623\n",
      "Epoch 32/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.6837 - accuracy: 0.77241s - l\n",
      "Epoch 33/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6748 - accuracy: 0.7727\n",
      "Epoch 34/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6579 - accuracy: 0.7789\n",
      "Epoch 35/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.6588 - accuracy: 0.7818\n",
      "Epoch 36/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.6431 - accuracy: 0.7840\n",
      "Epoch 37/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.6412 - accuracy: 0.7838\n",
      "Epoch 38/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.6244 - accuracy: 0.7911\n",
      "Epoch 39/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6191 - accuracy: 0.7935\n",
      "Epoch 40/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6157 - accuracy: 0.7923\n",
      "Epoch 41/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6085 - accuracy: 0.7972\n",
      "Epoch 42/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.6000 - accuracy: 0.7995\n",
      "Epoch 43/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.5922 - accuracy: 0.8021\n",
      "Epoch 44/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.5836 - accuracy: 0.8054\n",
      "Epoch 45/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.5795 - accuracy: 0.8058\n",
      "Epoch 46/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5753 - accuracy: 0.8054\n",
      "Epoch 47/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.5659 - accuracy: 0.8105\n",
      "Epoch 48/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.5620 - accuracy: 0.8113\n",
      "Epoch 49/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.5659 - accuracy: 0.8095\n",
      "Epoch 50/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.5516 - accuracy: 0.8143\n",
      "Epoch 51/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5396 - accuracy: 0.8166\n",
      "Epoch 52/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.5342 - accuracy: 0.8180\n",
      "Epoch 53/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5354 - accuracy: 0.8200\n",
      "Epoch 54/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5253 - accuracy: 0.8221\n",
      "Epoch 55/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.5245 - accuracy: 0.8239\n",
      "Epoch 56/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5161 - accuracy: 0.82650s - loss: 0.5160 - ac\n",
      "Epoch 57/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.5110 - accuracy: 0.8278\n",
      "Epoch 58/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5090 - accuracy: 0.8299\n",
      "Epoch 59/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5101 - accuracy: 0.8267\n",
      "Epoch 60/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.4967 - accuracy: 0.8339\n",
      "Epoch 61/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5022 - accuracy: 0.8310\n",
      "Epoch 62/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4944 - accuracy: 0.8337\n",
      "Epoch 63/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4865 - accuracy: 0.8369\n",
      "Epoch 64/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.4823 - accuracy: 0.8384\n",
      "Epoch 65/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.4817 - accuracy: 0.83950s - loss: 0.4816 - accuracy: \n",
      "Epoch 66/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4822 - accuracy: 0.8379\n",
      "Epoch 67/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4659 - accuracy: 0.8440\n",
      "Epoch 68/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4668 - accuracy: 0.84230s - loss: 0.4664 - accu\n",
      "Epoch 69/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4703 - accuracy: 0.8417\n",
      "Epoch 70/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.4547 - accuracy: 0.8477\n",
      "Epoch 71/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4553 - accuracy: 0.8459\n",
      "Epoch 72/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4543 - accuracy: 0.8471\n",
      "Epoch 73/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.4550 - accuracy: 0.8453\n",
      "Epoch 74/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4477 - accuracy: 0.8498\n",
      "Epoch 75/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4559 - accuracy: 0.8460\n",
      "Epoch 76/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4340 - accuracy: 0.8538\n",
      "Epoch 77/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4409 - accuracy: 0.8523\n",
      "Epoch 78/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.4340 - accuracy: 0.8547\n",
      "Epoch 79/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4359 - accuracy: 0.8547\n",
      "Epoch 80/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4245 - accuracy: 0.8586\n",
      "Epoch 81/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.4299 - accuracy: 0.8540\n",
      "Epoch 82/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4275 - accuracy: 0.8554\n",
      "Epoch 83/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4206 - accuracy: 0.8593\n",
      "Epoch 84/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4156 - accuracy: 0.8594\n",
      "Epoch 85/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4227 - accuracy: 0.8576\n",
      "Epoch 86/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4142 - accuracy: 0.8604\n",
      "Epoch 87/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.4116 - accuracy: 0.8631\n",
      "Epoch 88/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4065 - accuracy: 0.8618\n",
      "Epoch 89/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.4125 - accuracy: 0.8609\n",
      "Epoch 90/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4026 - accuracy: 0.8649\n",
      "Epoch 91/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3974 - accuracy: 0.8651\n",
      "Epoch 92/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.4005 - accuracy: 0.8640\n",
      "Epoch 93/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3994 - accuracy: 0.8646\n",
      "Epoch 94/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.4058 - accuracy: 0.8634\n",
      "Epoch 95/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3983 - accuracy: 0.8667\n",
      "Epoch 96/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.3955 - accuracy: 0.8662\n",
      "Epoch 97/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3917 - accuracy: 0.8675\n",
      "Epoch 98/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3970 - accuracy: 0.8681\n",
      "Epoch 99/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3943 - accuracy: 0.8668\n",
      "Epoch 100/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3803 - accuracy: 0.8711\n",
      "Epoch 101/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3797 - accuracy: 0.8717\n",
      "Epoch 102/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3812 - accuracy: 0.8717\n",
      "Epoch 103/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.3815 - accuracy: 0.8723\n",
      "Epoch 104/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3744 - accuracy: 0.8745\n",
      "Epoch 105/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.3786 - accuracy: 0.8717\n",
      "Epoch 106/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3765 - accuracy: 0.8739\n",
      "Epoch 107/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3635 - accuracy: 0.8769\n",
      "Epoch 108/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3674 - accuracy: 0.8734\n",
      "Epoch 109/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3666 - accuracy: 0.8768\n",
      "Epoch 110/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3623 - accuracy: 0.8782\n",
      "Epoch 111/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3645 - accuracy: 0.8777\n",
      "Epoch 112/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3664 - accuracy: 0.8769\n",
      "Epoch 113/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3609 - accuracy: 0.8797\n",
      "Epoch 114/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3526 - accuracy: 0.8802\n",
      "Epoch 115/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3533 - accuracy: 0.8796\n",
      "Epoch 116/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3520 - accuracy: 0.8809\n",
      "Epoch 117/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.3518 - accuracy: 0.8799\n",
      "Epoch 118/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3506 - accuracy: 0.8830\n",
      "Epoch 119/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3522 - accuracy: 0.8819\n",
      "Epoch 120/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3470 - accuracy: 0.8820\n",
      "Epoch 121/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3427 - accuracy: 0.8833\n",
      "Epoch 122/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3426 - accuracy: 0.8834\n",
      "Epoch 123/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3429 - accuracy: 0.8832\n",
      "Epoch 124/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3462 - accuracy: 0.8835\n",
      "Epoch 125/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3437 - accuracy: 0.8850\n",
      "Epoch 126/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3357 - accuracy: 0.8870\n",
      "Epoch 127/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3402 - accuracy: 0.8860\n",
      "Epoch 128/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3380 - accuracy: 0.8861\n",
      "Epoch 129/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3325 - accuracy: 0.8883\n",
      "Epoch 130/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3386 - accuracy: 0.8868\n",
      "Epoch 131/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3322 - accuracy: 0.8873\n",
      "Epoch 132/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3313 - accuracy: 0.8862\n",
      "Epoch 133/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3316 - accuracy: 0.8892\n",
      "Epoch 134/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3311 - accuracy: 0.8879\n",
      "Epoch 135/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.3316 - accuracy: 0.8897\n",
      "Epoch 136/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3172 - accuracy: 0.8920\n",
      "Epoch 137/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.3214 - accuracy: 0.8918\n",
      "Epoch 138/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3171 - accuracy: 0.8921\n",
      "Epoch 139/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3167 - accuracy: 0.8924\n",
      "Epoch 140/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3211 - accuracy: 0.8912\n",
      "Epoch 141/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3209 - accuracy: 0.8926\n",
      "Epoch 142/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3151 - accuracy: 0.8933\n",
      "Epoch 143/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3167 - accuracy: 0.8935\n",
      "Epoch 144/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3122 - accuracy: 0.8942\n",
      "Epoch 145/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3137 - accuracy: 0.8944\n",
      "Epoch 146/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3153 - accuracy: 0.8942\n",
      "Epoch 147/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3130 - accuracy: 0.8952\n",
      "Epoch 148/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3062 - accuracy: 0.8976\n",
      "Epoch 149/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3081 - accuracy: 0.8971\n",
      "Epoch 150/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3063 - accuracy: 0.8971\n",
      "Epoch 151/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3104 - accuracy: 0.8957\n",
      "Epoch 152/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2995 - accuracy: 0.8985\n",
      "Epoch 153/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3024 - accuracy: 0.8977\n",
      "Epoch 154/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.3056 - accuracy: 0.8971\n",
      "Epoch 155/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2964 - accuracy: 0.9010\n",
      "Epoch 156/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2950 - accuracy: 0.9009\n",
      "Epoch 157/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3057 - accuracy: 0.8978\n",
      "Epoch 158/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3008 - accuracy: 0.8980\n",
      "Epoch 159/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2974 - accuracy: 0.9002\n",
      "Epoch 160/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2988 - accuracy: 0.8994\n",
      "Epoch 161/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2934 - accuracy: 0.8999\n",
      "Epoch 162/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2938 - accuracy: 0.9021\n",
      "Epoch 163/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2886 - accuracy: 0.9026\n",
      "Epoch 164/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2954 - accuracy: 0.9005\n",
      "Epoch 165/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3043 - accuracy: 0.8974\n",
      "Epoch 166/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2914 - accuracy: 0.9014\n",
      "Epoch 167/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2851 - accuracy: 0.9042\n",
      "Epoch 168/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2900 - accuracy: 0.9041\n",
      "Epoch 169/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2837 - accuracy: 0.9041\n",
      "Epoch 170/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2815 - accuracy: 0.9050\n",
      "Epoch 171/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2846 - accuracy: 0.9036\n",
      "Epoch 172/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2814 - accuracy: 0.9040\n",
      "Epoch 173/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2810 - accuracy: 0.9056\n",
      "Epoch 174/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2882 - accuracy: 0.9039\n",
      "Epoch 175/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2750 - accuracy: 0.9076\n",
      "Epoch 176/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2950 - accuracy: 0.9003\n",
      "Epoch 177/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2842 - accuracy: 0.9035\n",
      "Epoch 178/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2776 - accuracy: 0.9060\n",
      "Epoch 179/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2709 - accuracy: 0.9083\n",
      "Epoch 180/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2741 - accuracy: 0.9084\n",
      "Epoch 181/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2759 - accuracy: 0.90691s - los\n",
      "Epoch 182/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2780 - accuracy: 0.9055\n",
      "Epoch 183/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2718 - accuracy: 0.9074\n",
      "Epoch 184/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2660 - accuracy: 0.9103\n",
      "Epoch 185/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2652 - accuracy: 0.9111\n",
      "Epoch 186/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2794 - accuracy: 0.9060\n",
      "Epoch 187/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2731 - accuracy: 0.9091\n",
      "Epoch 188/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2698 - accuracy: 0.91000s - loss: 0.2692 - accura\n",
      "Epoch 189/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2651 - accuracy: 0.9114\n",
      "Epoch 190/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2702 - accuracy: 0.9099\n",
      "Epoch 191/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2645 - accuracy: 0.9106\n",
      "Epoch 192/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2638 - accuracy: 0.9105\n",
      "Epoch 193/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2696 - accuracy: 0.9096\n",
      "Epoch 194/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2606 - accuracy: 0.9120\n",
      "Epoch 195/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2641 - accuracy: 0.9102\n",
      "Epoch 196/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2622 - accuracy: 0.9114\n",
      "Epoch 197/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2599 - accuracy: 0.9133\n",
      "Epoch 198/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2557 - accuracy: 0.9130\n",
      "Epoch 199/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2614 - accuracy: 0.9123\n",
      "Epoch 200/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2570 - accuracy: 0.91290s - loss: 0.2574 - accuracy\n",
      "Epoch 201/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2599 - accuracy: 0.9132\n",
      "Epoch 202/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2608 - accuracy: 0.9128\n",
      "Epoch 203/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2553 - accuracy: 0.9148\n",
      "Epoch 204/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2546 - accuracy: 0.9146\n",
      "Epoch 205/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2546 - accuracy: 0.9136\n",
      "Epoch 206/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2509 - accuracy: 0.9155\n",
      "Epoch 207/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2554 - accuracy: 0.9140\n",
      "Epoch 208/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2477 - accuracy: 0.9178\n",
      "Epoch 209/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2492 - accuracy: 0.9171\n",
      "Epoch 210/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2506 - accuracy: 0.9152\n",
      "Epoch 211/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2524 - accuracy: 0.9146\n",
      "Epoch 212/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2512 - accuracy: 0.9156\n",
      "Epoch 213/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2475 - accuracy: 0.9174\n",
      "Epoch 214/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2492 - accuracy: 0.9170\n",
      "Epoch 215/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2484 - accuracy: 0.9180\n",
      "Epoch 216/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2436 - accuracy: 0.9181\n",
      "Epoch 217/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2453 - accuracy: 0.9170\n",
      "Epoch 218/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2472 - accuracy: 0.9171\n",
      "Epoch 219/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2460 - accuracy: 0.9168\n",
      "Epoch 220/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2451 - accuracy: 0.9172\n",
      "Epoch 221/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2392 - accuracy: 0.9206\n",
      "Epoch 222/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2417 - accuracy: 0.9180\n",
      "Epoch 223/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2397 - accuracy: 0.9182\n",
      "Epoch 224/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2419 - accuracy: 0.9187\n",
      "Epoch 225/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2335 - accuracy: 0.9212\n",
      "Epoch 226/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2375 - accuracy: 0.9202\n",
      "Epoch 227/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2423 - accuracy: 0.91870s - loss: 0.2422 - accura\n",
      "Epoch 228/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2399 - accuracy: 0.9197\n",
      "Epoch 229/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2509 - accuracy: 0.9170\n",
      "Epoch 230/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2307 - accuracy: 0.9229\n",
      "Epoch 231/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2425 - accuracy: 0.9186\n",
      "Epoch 232/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2379 - accuracy: 0.9215\n",
      "Epoch 233/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2357 - accuracy: 0.9210\n",
      "Epoch 234/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2442 - accuracy: 0.9167\n",
      "Epoch 235/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2344 - accuracy: 0.9205\n",
      "Epoch 236/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2336 - accuracy: 0.9212\n",
      "Epoch 237/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2345 - accuracy: 0.9208\n",
      "Epoch 238/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2296 - accuracy: 0.9226\n",
      "Epoch 239/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2278 - accuracy: 0.9230\n",
      "Epoch 240/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2289 - accuracy: 0.9231\n",
      "Epoch 241/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2332 - accuracy: 0.9226\n",
      "Epoch 242/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2374 - accuracy: 0.9196\n",
      "Epoch 243/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2291 - accuracy: 0.9228\n",
      "Epoch 244/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2349 - accuracy: 0.9206\n",
      "Epoch 245/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2323 - accuracy: 0.9224\n",
      "Epoch 246/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2274 - accuracy: 0.9234\n",
      "Epoch 247/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2224 - accuracy: 0.9256\n",
      "Epoch 248/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2309 - accuracy: 0.9226\n",
      "Epoch 249/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2230 - accuracy: 0.9265\n",
      "Epoch 250/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2232 - accuracy: 0.9258\n",
      "Epoch 251/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2246 - accuracy: 0.9242\n",
      "Epoch 252/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2269 - accuracy: 0.9250\n",
      "Epoch 253/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2224 - accuracy: 0.92610s - loss: 0.2223 - ac\n",
      "Epoch 254/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2264 - accuracy: 0.9247\n",
      "Epoch 255/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2216 - accuracy: 0.9251\n",
      "Epoch 256/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2245 - accuracy: 0.9236\n",
      "Epoch 257/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2423 - accuracy: 0.9189\n",
      "Epoch 258/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2229 - accuracy: 0.9253\n",
      "Epoch 259/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2209 - accuracy: 0.9264\n",
      "Epoch 260/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2152 - accuracy: 0.9267\n",
      "Epoch 261/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2203 - accuracy: 0.9261\n",
      "Epoch 262/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2298 - accuracy: 0.9236\n",
      "Epoch 263/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2163 - accuracy: 0.9268\n",
      "Epoch 264/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2128 - accuracy: 0.9276\n",
      "Epoch 265/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2360 - accuracy: 0.9216\n",
      "Epoch 266/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2185 - accuracy: 0.9269\n",
      "Epoch 267/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2152 - accuracy: 0.9273\n",
      "Epoch 268/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2211 - accuracy: 0.9255\n",
      "Epoch 269/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2169 - accuracy: 0.9278\n",
      "Epoch 270/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2151 - accuracy: 0.9274\n",
      "Epoch 271/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2127 - accuracy: 0.9286\n",
      "Epoch 272/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2122 - accuracy: 0.9285\n",
      "Epoch 273/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2149 - accuracy: 0.9292\n",
      "Epoch 274/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2121 - accuracy: 0.9287\n",
      "Epoch 275/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2223 - accuracy: 0.9266\n",
      "Epoch 276/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2208 - accuracy: 0.9271\n",
      "Epoch 277/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2177 - accuracy: 0.9263\n",
      "Epoch 278/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2091 - accuracy: 0.9308\n",
      "Epoch 279/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2130 - accuracy: 0.9292\n",
      "Epoch 280/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2110 - accuracy: 0.9288\n",
      "Epoch 281/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2119 - accuracy: 0.9291\n",
      "Epoch 282/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2120 - accuracy: 0.9289\n",
      "Epoch 283/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2133 - accuracy: 0.9272\n",
      "Epoch 284/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2150 - accuracy: 0.9293\n",
      "Epoch 285/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2023 - accuracy: 0.9321\n",
      "Epoch 286/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.2068 - accuracy: 0.9311\n",
      "Epoch 287/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2131 - accuracy: 0.9287\n",
      "Epoch 288/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2037 - accuracy: 0.9315\n",
      "Epoch 289/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2131 - accuracy: 0.9299\n",
      "Epoch 290/350\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.92 - 37s 47ms/step - loss: 0.2105 - accuracy: 0.9295\n",
      "Epoch 291/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2129 - accuracy: 0.9306\n",
      "Epoch 292/350\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 0.2046 - accuracy: 0.9317\n",
      "Epoch 293/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.2065 - accuracy: 0.9321\n",
      "Epoch 294/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2060 - accuracy: 0.9318\n",
      "Epoch 295/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2134 - accuracy: 0.9284\n",
      "Epoch 296/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2036 - accuracy: 0.9314\n",
      "Epoch 297/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2022 - accuracy: 0.9327\n",
      "Epoch 298/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2028 - accuracy: 0.9326\n",
      "Epoch 299/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2046 - accuracy: 0.9315\n",
      "Epoch 300/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.2018 - accuracy: 0.9320\n",
      "Epoch 301/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1999 - accuracy: 0.9329\n",
      "Epoch 302/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2026 - accuracy: 0.9325\n",
      "Epoch 303/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2042 - accuracy: 0.9320\n",
      "Epoch 304/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.2006 - accuracy: 0.9325\n",
      "Epoch 305/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2050 - accuracy: 0.9320\n",
      "Epoch 306/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1931 - accuracy: 0.9348\n",
      "Epoch 307/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.1949 - accuracy: 0.9339\n",
      "Epoch 308/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.1988 - accuracy: 0.9335\n",
      "Epoch 309/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.1976 - accuracy: 0.9347\n",
      "Epoch 310/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1982 - accuracy: 0.9338\n",
      "Epoch 311/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1959 - accuracy: 0.9338\n",
      "Epoch 312/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.1991 - accuracy: 0.9334\n",
      "Epoch 313/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1962 - accuracy: 0.9349\n",
      "Epoch 314/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1953 - accuracy: 0.9348\n",
      "Epoch 315/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1977 - accuracy: 0.9342\n",
      "Epoch 316/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.1943 - accuracy: 0.9346\n",
      "Epoch 317/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2017 - accuracy: 0.9332\n",
      "Epoch 318/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.2022 - accuracy: 0.9330\n",
      "Epoch 319/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1969 - accuracy: 0.9334\n",
      "Epoch 320/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1980 - accuracy: 0.9322\n",
      "Epoch 321/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1914 - accuracy: 0.9352\n",
      "Epoch 322/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1884 - accuracy: 0.9373\n",
      "Epoch 323/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1961 - accuracy: 0.9348\n",
      "Epoch 324/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.1908 - accuracy: 0.9349\n",
      "Epoch 325/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1928 - accuracy: 0.9362\n",
      "Epoch 326/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1863 - accuracy: 0.9382\n",
      "Epoch 327/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1859 - accuracy: 0.9385\n",
      "Epoch 328/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.2047 - accuracy: 0.9333\n",
      "Epoch 329/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1922 - accuracy: 0.9357\n",
      "Epoch 330/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1854 - accuracy: 0.9383\n",
      "Epoch 331/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1916 - accuracy: 0.9366\n",
      "Epoch 332/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1856 - accuracy: 0.9385\n",
      "Epoch 333/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1835 - accuracy: 0.9378\n",
      "Epoch 334/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1844 - accuracy: 0.9379\n",
      "Epoch 335/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1887 - accuracy: 0.9373\n",
      "Epoch 336/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1917 - accuracy: 0.9356\n",
      "Epoch 337/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1910 - accuracy: 0.9368\n",
      "Epoch 338/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1846 - accuracy: 0.9385\n",
      "Epoch 339/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.1846 - accuracy: 0.9374\n",
      "Epoch 340/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.1866 - accuracy: 0.9375\n",
      "Epoch 341/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1843 - accuracy: 0.93700s - loss: 0.1845 - accu\n",
      "Epoch 342/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2105 - accuracy: 0.9322\n",
      "Epoch 343/350\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.1848 - accuracy: 0.9385\n",
      "Epoch 344/350\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.1829 - accuracy: 0.9387\n",
      "Epoch 345/350\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.1845 - accuracy: 0.9380\n",
      "Epoch 346/350\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1836 - accuracy: 0.9381\n",
      "Epoch 347/350\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.1895 - accuracy: 0.9376\n",
      "Epoch 348/350\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.1835 - accuracy: 0.9394\n",
      "Epoch 349/350\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.1873 - accuracy: 0.9377\n",
      "Epoch 350/350\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.1825 - accuracy: 0.9395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size, shuffle=True),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(dirc+'/cnn_weights_FINAL.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predit labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1601797565821,
     "user": {
      "displayName": "maral rasooli jaberi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjyEFecHlaryGBQ93clEnZ0HQ8ZEDudBRmfeJomVg=s64",
      "userId": "05542248541013606603"
     },
     "user_tz": 240
    },
    "id": "p0jt4u9nFCwC",
    "outputId": "37abcc4f-834f-4c3a-ad60-eaf62137d986"
   },
   "outputs": [],
   "source": [
    "prd = model.predict(x_test)\n",
    "prd_y = np.argmax(prd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [int(x_dir.split('\\\\')[-1].split('.')[0]) for x_dir in test_dir] #get test images' names(id)\n",
    "pred_dic = {'id':ids, 'label':prd_y}\n",
    "pred_df = pd.DataFrame(data=pred_dic)\n",
    "pred_df.to_csv(dirc+\"/test_pred_FINAL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "0        0      0\n",
       "1        1      2\n",
       "2       10      7\n",
       "3      100      2\n",
       "4     1000      9\n",
       "...    ...    ...\n",
       "9995  9995      0\n",
       "9996  9996      0\n",
       "9997  9997      5\n",
       "9998  9998      5\n",
       "9999  9999      1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(dirc+'/test_pred_FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'], color='blue', label='train')\n",
    "\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of CFAR.ipynb",
   "provenance": [
    {
     "file_id": "1OzEccZLhFAKrew2Q_JZKiNuyvNpa70KP",
     "timestamp": 1602090700972
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
